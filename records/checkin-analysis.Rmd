---
title: 'checkin data: Regression analysis'
output: html_document
author: "Ming Li"
date: "Monday, August 4, 2014"
---
### Target
The goal of this work is to explore the relationships between user's interest (here represented by "checkin category") and some contextual factors such as time, weather, sequence, spatial, etc.

First, we load the libraries, functions, and data into the workspace.
```{r, include=FALSE}
# basic preparation for experiment: load libraries, functions, data, etc.
library(scales)
library(ggplot2)
source("D:\\GitRepos\\work\\fun\\mathmatrixcal.R")
basedir = "D:\\Experiments\\R\\"

# load checkin
checkin = read.csv( paste0(basedir, "data\\userA.csv"), 
                       header=TRUE, sep=",",  
                       na.strings = "none",
                       colClasses = c("numeric","numeric","factor",
                                      "factor", "numeric","numeric",
                                      "numeric","character","factor",
                                      "factor")
                       )

## load weather
weather = read.csv( paste0(basedir, "data\\weather.csv"), 
                       header=TRUE, sep=",", na.strings = c("-9999","Unknown"),
                       colClasses = c("numeric","numeric","numeric","character",
                                      "numeric","factor","numeric","numeric",
                                      "numeric","numeric","numeric","numeric",
                                      "numeric","numeric")
)


weather$fog=as.logical(weather$fog)
weather$rain=as.logical(weather$rain)
weather$snow=as.logical(weather$snow)
weather$thunder=as.logical(weather$thunder)
weather$tornado=as.logical(weather$tornado)

checkin$datetime = strptime( strtrim(checkin$localtime,19),format="%Y-%m-%d %H:%M:%S")
## join checkin data with weather data based on timestamps 
checkin = joindfsbytime(checkin, weather)
#rm(DF_checkin, DF_weather)

## deal with time 
checkin$hour = as.factor(format(checkin$datetime,"%H"))
checkin$hour.i = categorizedhour(checkin$hour)
checkin$yearday = format(checkin$datetime,"%j")
checkin$weekday = format(checkin$datetime,"%w")
checkin$isweekend = as.factor(ifelse(( checkin$weekday>5 | checkin$weekday<1),
    "Weekend", "Workday"))

## add record for last checkin
checkin = copylastcheckinrec(checkin)
checkin=checkin[complete.cases(checkin$conds),]
```
Have a look at the data:
```{r, echo=FALSE}
summary(checkin)
```


### Factor selections

#### 1. Chi-square independence test
This is aimed to test whether there are correlations among the factors.

#### 2. Multi-factor analysis of variance (MFA), multi-way ANOVA
ref: http://www.itl.nist.gov/div898/handbook/eda/section3/eda355.htm

Because each factor can take on a certain number of values (i.e. levels of a factor), and the number of levels can vary between factors. For designed experiments, the number of levels for a given factor tends to be small. 


#### 3. Multiple correspondence analysis (MCA)

ref: http://factominer.free.fr/classical-methods/multiple-correspondence-analysis.html

It is used for nominal categorical data, and to detect and represent underlying structures in a dataset. It can be regarded as the counterpart of PCA for categorical data. 

```{r, echo=FALSE, fig.width=10, fig.height=8}
library(FactoMineR)
checkin.test=data.frame(checkin$cate_l1,checkin$conds,checkin$hour, checkin$isweekend, checkin$temperatur)
#checkin.test=checkin.test[which(checkin$conds=="Snow"),]
#png("111.png", width=1000, height=1000)
par(mfrow=c(2,2))
checkin.mca = MCA(checkin.test, ncp=2, quanti.sup=5,quali.sup=c(2))
#dev.off()
#png("222.png", width=1000, height=1000)
#par(mfrow=c(2,2))
#checkin.mca2 = MCA(checkin.test, ncp=2, quanti.sup=5,quali.sup=c(3,4))
#dev.off()
```


### Regression Model
The data that we are dealing with is categorical. Seveal non-linear regression models are powerful with such kind of data, such as *Multinomial Logistic Regression Model* and *Log Linear Regression model*. 

#### 1. Multinomial logistic regression model 
This model generalizes logistic regression (binary response) to multiclass problems (more than two possible discrete outomes). It similarly uses a linking function to link the categorical output to a continuous response.
$$ f(x)_{i}=log\frac{P(Y=i)}{P(Y=K)}=\sum \beta_{i,j}\cdot x_{j} $$
where $x_{j}$ are the predictors; $K$ is the baseline, and it can be any of the possible output categories; $i$ is any other possible categories except $K$. Therefore, it relies on the assumption of IIA(independence of irrelevant alternatives). Suppose there are $I$ possible categories, then there will be $(I-1)$ equations $f(x)$. $log\frac{P(Y=i)}{P(Y=K)}$ in fact models the log odds of choosing category $i$ against baseline $K$.

Multinomial logistic regression model can deal with both discrete and continuous predictors $x_{i}$. When the predictor is cateogical, it will be treated as dummy variables.

#### 2. Log linear regression model 
Log linear analysis allows us to look for relationships among variables in a multiway contingency table. It in fact models the expected frequency of each cell in the contingency table based on all interactions.
$$F_{ij}=\lambda + \lambda_{i} + \lambda_{j} + \lambda_{ij}$$
where $F_{ij}$ is the expected frequency, $\lambda_{i}$ is the influences from varaible $i$, and $\lambda_{j}$ is the influences from varaible $j$. If the interactions between $i$ and $j$ are considered, $\lambda_{ij}$ describes the influences from the interactions.

Since it is based on contingency table, log linear regression model can only deal with categorical data (both predictors and responsed must be categorical). The good side for log linear model is that it is very convienient to perform analysis of variance, and easily specify constrained versions of the saturated model. This is possible with multinomial models using what are called *constrained multinomial models* but it is a bit more tedious. 

#### 3. The challenges in using regression
There are several key problems in analyzing the checkin data with regression models.
    
* determine the variables to be included in tht regression
    + the collinearity should be low; otherwise the model will be unstable;  
    + the included variables should contribute to the majority of the total variance in the output response;  
* confidence level for the efficients;
* confidence level for the regression model.

Key challenges here includes:

* too many variables: 
    + computation;
    + the collinearity diagnostics would be tedious; 
    + the interactions between each other would be complicated;
* we have a temporal-spatial problem here:
    + integraing temporal weights for seqential factor;
    + integrating geographical weights for spatial factor;
    + it is not easy to add weights to categorical data;
    + with weights, we will deal with both discrete and continuous variables.
    
ref: http://www.unistat.com/guide/multinomial-regression/

### Experimental Analysis

#### 1. chi-square tests for independence
We are interested to find whether there're any relations between them (whether we can reject the null hypothesis $H_{0}$ that these factors are in fact independent from each other). Therefore we begin by taking the several contingency tables from the data.(p.s.: We will leave the spatial factors in the end.)
```{r}
# venue_cate v.s. hour of day
cate.hour = xtabs(~hour+cate_l1, data=checkin)
cate.hour = as.table(cate.hour[rowSums(cate.hour)>0,colSums(cate.hour)>0])
chisq.test(cate.hour, simulate.p.value = TRUE)
# venue_cate v.s. categorized hour
cate.hour = xtabs(~hour.i+cate_l1, data=checkin)
cate.hour = as.table(cate.hour[rowSums(cate.hour)>0,colSums(cate.hour)>0])
chisq.test(cate.hour, simulate.p.value = TRUE)
# venue_cate v.s. weekend/workday
cate.weekend = xtabs(~isweekend+cate_l1, data=checkin)
cate.weekend = as.table(cate.weekend[rowSums(cate.weekend)>0,colSums(cate.weekend)>0])
chisq.test(cate.weekend, simulate.p.value = TRUE)
# venue_cate v.s. weather condition
cate.conds = xtabs(~conds+cate_l1, data=checkin)
cate.conds = as.table(cate.conds[rowSums(cate.conds)>0,colSums(cate.conds)>0])
chisq.test(cate.conds, simulate.p.value = TRUE)
# venue_cate v.s. last venue_cate (sequential factor)
cate.cate = xtabs(~last_cate_l1+cate_l1, data=checkin)
cate.cate = as.table(cate.cate[rowSums(cate.cate)>0,colSums(cate.cate)>0])
chisq.test(cate.cate, simulate.p.value = TRUE)
```

At the first glance, the chi-square tests indicate that there should be interactions between category v.s. hour, weekend or not, the last visited cateogry with p-value all below 5%. The p-value for category v.s. weather condition is rather high at 20%. It seems we should accept the null hypothesis that they are not related. However, we should still keep an eye on it because in these chi-square tests, only the single interaction was considered; while these factors might also affet the response in an interacted way. 

#### 2. Log-linear analysis 
```{r}
cate.hour = xtabs(~hour.i+cate_l1, data=checkin)
freq.cate.hour = as.data.frame(cate.hour)
loglin.sat.cate.hour = glm(Freq~cate_l1*hour.i, 
                           data=freq.cate.hour, family=poisson)
#summary(loglin.sat.cate.hour)
anova(loglin.sat.cate.hour)

cate.hour.isweekend = xtabs(~hour.i+cate_l1+isweekend, data=checkin)
freq.cate.hour.isweekend = as.data.frame(cate.hour.isweekend)
loglin.sat.cate.hour.isweekend = glm(Freq~cate_l1*hour.i*isweekend, 
                           data=freq.cate.hour.isweekend, family=poisson)
#summary(loglin.sat.cate.hour.isweekend)
anova(loglin.sat.cate.hour.isweekend)
```

#### 3. Multinomial logistic regression

```
library(nnet)
tmodel1<-multinom(cate_l1~ hour.i+isweekend+conds+windspd+temperatur,
                      data=checkin,maxit = 1000)
tsummary1 = summary(tmodel1)
z1 = tsummary1$coefficients/tsummary1$standard.errors
p1 = (1 - pnorm(abs(z1), 0, 1)) * 2

```


